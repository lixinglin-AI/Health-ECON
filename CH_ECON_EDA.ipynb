{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1f8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b209c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2014 County Health Rankings Data - v6.xls: 3141 rows, Year: 2014\n",
      "Processed 2015 County Health Rankings Data - v3.xls: 3141 rows, Year: 2015\n",
      "Processed 2016 County Health Rankings Data - v3.xls: 3141 rows, Year: 2016\n",
      "Processed 2017CountyHealthRankingsData.xls: 3136 rows, Year: 2017\n",
      "Processed 2018 County Health Rankings Data - v2.xls: 3142 rows, Year: 2018\n",
      "Processed 2019 County Health Rankings Data - v3.xls: 3142 rows, Year: 2019\n",
      "Processed 2020 County Health Rankings Data - v2.xlsx: 3193 rows, Year: 2020\n",
      "Processed 2021 County Health Rankings Data - v1.xlsx: 3193 rows, Year: 2021\n",
      "Processed 2022 County Health Rankings Data - v1.xlsx: 3193 rows, Year: 2022\n",
      "Processed 2023 County Health Rankings Data - v2.xlsx: 3193 rows, Year: 2023\n",
      "Processed 2024_county_health_release_data_-_v1 (1).xlsx: 3201 rows, Year: 2024\n"
     ]
    }
   ],
   "source": [
    "# Define the folder path\n",
    "folder_path = r\"C:\\Users\\liuc\\Desktop\\talent rentention\\Healthdata2\"\n",
    "\n",
    "# Get all Excel files\n",
    "excel_files = sorted([f for f in os.listdir(folder_path) if f.endswith(('.xlsx', '.xls'))])\n",
    "\n",
    "# Column name mapping dictionary to standardize names\n",
    "column_mapping = {\n",
    "    # FIPS, State, County (consistent)\n",
    "    'FIPS': 'FIPS',\n",
    "    'State': 'State',\n",
    "    'County': 'County',\n",
    "    \n",
    "    # Deaths/Premature Deaths variations\n",
    "    'pre mature Deaths': 'Premature Deaths',\n",
    "    'premature Deaths': 'Premature Deaths',\n",
    "    'Premature death': 'Premature Deaths',\n",
    "    '# Deaths': 'Premature Deaths',\n",
    "    'Deaths': 'Premature Deaths',\n",
    "    \n",
    "    # Fair/Poor Health variations\n",
    "    '% Fair or Poor Health': '% Fair or Poor Health',\n",
    "    '% Fair/Poor': '% Fair or Poor Health',\n",
    "    \n",
    "    # Physically Unhealthy Days\n",
    "    'Physically Unhealthy Days': 'Physically Unhealthy Days',\n",
    "    'Average Number of Physically Unhealthy Days': 'Physically Unhealthy Days',\n",
    "    \n",
    "    # Mentally Unhealthy Days\n",
    "    'Mentally Unhealthy Days': 'Mentally Unhealthy Days',\n",
    "    'Average Number of Mentally Unhealthy Days': 'Mentally Unhealthy Days',\n",
    "    \n",
    "    # Low Birth Weight\n",
    "    '% low birth weight': '% Low Birthweight',\n",
    "    '% Low birthweight': '% Low Birthweight',\n",
    "    '% Low Birthweight': '% Low Birthweight',\n",
    "    '% LBW': '% Low Birthweight',\n",
    "    \n",
    "    # Smoking\n",
    "    '% Smokers': '% Smokers',\n",
    "    '% Adults Reporting Currently Smoking': '% Smokers',\n",
    "    \n",
    "    # Obesity\n",
    "    '% Obese': '% Adults with Obesity',\n",
    "    '% Adults with Obesity': '% Adults with Obesity',\n",
    "    \n",
    "    # Food Environment Index (consistent)\n",
    "    'Food Environment Index': 'Food Environment Index',\n",
    "    \n",
    "    # Physical Activity/Exercise Access\n",
    "    '% With Access': '% With Access to Exercise Opportunities',\n",
    "    '% With Access exercise': '% With Access to Exercise Opportunities',\n",
    "    '% With Access to Exercise Opportunities': '% With Access to Exercise Opportunities',\n",
    "    '% Physically Inactive': '% Physically Inactive',\n",
    "    \n",
    "    # Excessive Drinking (consistent)\n",
    "    '% Excessive Drinking': '% Excessive Drinking',\n",
    "    \n",
    "    # Driving Deaths\n",
    "    '# Alcohol-Impaired Driving Deaths': '# Alcohol-Impaired Driving Deaths',\n",
    "    '# Driving Deaths': '# Driving Deaths',\n",
    "    \n",
    "    # Teen Birth Rate (consistent)\n",
    "    'Teen Birth Rate': 'Teen Birth Rate',\n",
    "    \n",
    "    # Uninsured\n",
    "    '# Uninsured': '# Uninsured',\n",
    "    '% Uninsured': '% Uninsured',\n",
    "    \n",
    "    # Primary Care Physicians\n",
    "    'PCP Rate': 'Primary Care Physicians Rate',\n",
    "    'Primary Care Physicians Ratio': 'Primary Care Physicians Rate',\n",
    "    'Primary Care Physicians Rate': 'Primary Care Physicians Rate',\n",
    "    \n",
    "    # Medicare\n",
    "    '# Medicare enrollees': '# Medicare Enrollees',\n",
    "    '# Medicare Enrollees': '# Medicare Enrollees',\n",
    "    \n",
    "    # Preventable Hospitalizations\n",
    "    'Preventable Hosp. Rate': 'Preventable Hospitalization Rate',\n",
    "    'Preventable Hospitalization Rate': 'Preventable Hospitalization Rate',\n",
    "    \n",
    "    # Education\n",
    "    '% Some College': '% Some College',\n",
    "    \n",
    "    # Unemployment\n",
    "    '% Unemployed': '% Unemployed',\n",
    "    \n",
    "    # Child Poverty\n",
    "    '% Children in Poverty': '% Children in Poverty',\n",
    "    \n",
    "    # Income Ratio\n",
    "    'Income Ratio': 'Income Ratio',\n",
    "    \n",
    "    # Single-Parent Households\n",
    "    '% Single-Parent Households': '% Children in Single-Parent Households',\n",
    "    '% Children in Single-Parent Households': '% Children in Single-Parent Households',\n",
    "    \n",
    "    # Social Association\n",
    "    'Association Rate': 'Social Association Rate',\n",
    "    'Social Association Rate': 'Social Association Rate',\n",
    "    \n",
    "    # Crime\n",
    "    'Violent Crime Rate': 'Violent Crime Rate',\n",
    "    \n",
    "    # Housing\n",
    "    '% Severe Housing Problems': '% Severe Housing Problems',\n",
    "    \n",
    "    # Commuting\n",
    "    '% Drive Alone': '% Drive Alone to Work',\n",
    "    '% Drive Alone to Work': '% Drive Alone to Work',\n",
    "    'Long Commute - Drives Alone': '% Long Commute - Drives Alone',\n",
    "    '% Long Commute - Drives Alone': '% Long Commute - Drives Alone',\n",
    "    \n",
    "    # Dentist columns (2023 specific)\n",
    "    'Quartile': 'Quartile',\n",
    "    '# Dentists': '# Dentists',\n",
    "    'Dentist Rate': 'Dentist Rate',\n",
    "    'Dentist Ratio': 'Dentist Ratio'\n",
    "}\n",
    "\n",
    "# List to store all dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Process each file\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    try:\n",
    "        # Extract year from filename\n",
    "        if '2014' in file:\n",
    "            year = 2014\n",
    "        elif '2015' in file:\n",
    "            year = 2015\n",
    "        elif '2016' in file:\n",
    "            year = 2016\n",
    "        elif '2017' in file:\n",
    "            year = 2017\n",
    "        elif '2018' in file:\n",
    "            year = 2018\n",
    "        elif '2019' in file:\n",
    "            year = 2019\n",
    "        elif '2020' in file:\n",
    "            year = 2020\n",
    "        elif '2021' in file:\n",
    "            year = 2021\n",
    "        elif '2022' in file:\n",
    "            year = 2022\n",
    "        elif '2023' in file:\n",
    "            year = 2023\n",
    "        elif '2024' in file:\n",
    "            year = 2024\n",
    "        else:\n",
    "            year = 'Unknown'\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path, sheet_name='Ranked Measure Data')\n",
    "        \n",
    "        # Add year column\n",
    "        df['Year'] = year\n",
    "        \n",
    "        # Rename columns using the mapping\n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        # Add to list\n",
    "        all_dfs.append(df)\n",
    "        \n",
    "        print(f\"Processed {file}: {len(df)} rows, Year: {year}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {str(e)}\")\n",
    "\n",
    "# Get all unique columns across all dataframes\n",
    "all_columns = set()\n",
    "for df in all_dfs:\n",
    "    all_columns.update(df.columns)\n",
    "\n",
    "# Remove 'Year' from all_columns as we'll add it at a specific position\n",
    "all_columns.discard('Year')\n",
    "\n",
    "# Define the order of columns (put most important ones first)\n",
    "column_order = ['Year', 'FIPS', 'State', 'County'] + sorted(list(all_columns - {'FIPS', 'State', 'County'}))\n",
    "\n",
    "# Standardize all dataframes to have the same columns\n",
    "standardized_dfs = []\n",
    "for df in all_dfs:\n",
    "    # Add missing columns with NaN\n",
    "    for col in column_order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    \n",
    "    # Reorder columns\n",
    "    df = df[column_order]\n",
    "    standardized_dfs.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_df = pd.concat(standardized_dfs, ignore_index=True)\n",
    "\n",
    "# Sort by Year, State, and County\n",
    "combined_df = combined_df.sort_values(['Year', 'State', 'County'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50003fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (34816, 38)\n",
      "Rows with null County: 255\n",
      "After removing null counties: (34561, 38)\n",
      "\n",
      "============================================================\n",
      "Columns with missing data:\n",
      "============================================================\n",
      "                                     Column  Missing_Count  Total_Rows  \\\n",
      "25                             Dentist Rate          31505       34561   \n",
      "5                                # Dentists          31505       34561   \n",
      "26                            Dentist Ratio          31505       34561   \n",
      "23                  % With Access exercise           31498       34561   \n",
      "34                                 Quartile          31479       34561   \n",
      "17                    % Physically Inactive          31419       34561   \n",
      "8                               # Uninsured          25139       34561   \n",
      "7                      # Medicare Enrollees          19499       34561   \n",
      "31                         Premature Deaths           8309       34561   \n",
      "37                       Violent Crime Rate           7921       34561   \n",
      "32         Preventable Hospitalization Rate           3913       34561   \n",
      "24  % With Access to Exercise Opportunities           3461       34561   \n",
      "28                             Income Ratio           3184       34561   \n",
      "12                    % Drive Alone to Work           3152       34561   \n",
      "35                  Social Association Rate           3148       34561   \n",
      "13                     % Excessive Drinking           1842       34561   \n",
      "36                          Teen Birth Rate           1602       34561   \n",
      "33             Primary Care Physicians Rate           1584       34561   \n",
      "16                        % Low Birthweight           1258       34561   \n",
      "29                  Mentally Unhealthy Days           1114       34561   \n",
      "19                                % Smokers            870       34561   \n",
      "14                    % Fair or Poor Health            810       34561   \n",
      "30                Physically Unhealthy Days            678       34561   \n",
      "4         # Alcohol-Impaired Driving Deaths            306       34561   \n",
      "6                          # Driving Deaths            306       34561   \n",
      "27                   Food Environment Index            184       34561   \n",
      "11   % Children in Single-Parent Households             21       34561   \n",
      "10                    % Children in Poverty             19       34561   \n",
      "21                             % Unemployed             19       34561   \n",
      "22                              % Uninsured             18       34561   \n",
      "15            % Long Commute - Drives Alone              9       34561   \n",
      "9                     % Adults with Obesity              9       34561   \n",
      "20                           % Some College              8       34561   \n",
      "18                % Severe Housing Problems              7       34561   \n",
      "\n",
      "    Missing_Percentage  \n",
      "25           91.157663  \n",
      "5            91.157663  \n",
      "26           91.157663  \n",
      "23           91.137409  \n",
      "34           91.082434  \n",
      "17           90.908828  \n",
      "8            72.738057  \n",
      "7            56.419085  \n",
      "31           24.041550  \n",
      "37           22.918897  \n",
      "32           11.322010  \n",
      "24           10.014178  \n",
      "28            9.212696  \n",
      "12            9.120106  \n",
      "35            9.108533  \n",
      "13            5.329707  \n",
      "36            4.635283  \n",
      "33            4.583201  \n",
      "16            3.639941  \n",
      "29            3.223286  \n",
      "19            2.517288  \n",
      "14            2.343682  \n",
      "30            1.961749  \n",
      "4             0.885391  \n",
      "6             0.885391  \n",
      "27            0.532392  \n",
      "11            0.060762  \n",
      "10            0.054975  \n",
      "21            0.054975  \n",
      "22            0.052082  \n",
      "15            0.026041  \n",
      "9             0.026041  \n",
      "20            0.023147  \n",
      "18            0.020254  \n",
      "\n",
      "============================================================\n",
      "Columns to remove (>50% missing): 8\n",
      "============================================================\n",
      "  - # Dentists: 91.2% missing\n",
      "  - # Medicare Enrollees: 56.4% missing\n",
      "  - # Uninsured: 72.7% missing\n",
      "  - % Physically Inactive: 90.9% missing\n",
      "  - % With Access exercise : 91.1% missing\n",
      "  - Dentist Rate: 91.2% missing\n",
      "  - Dentist Ratio: 91.2% missing\n",
      "  - Quartile: 91.1% missing\n",
      "\n",
      "============================================================\n",
      "Final cleaned dataset summary:\n",
      "============================================================\n",
      "Shape: (34561, 30)\n",
      "Rows: 34561\n",
      "Columns: 30\n",
      "\n",
      "Remaining columns (30):\n",
      "   1. Year                                               (100.0% data available)\n",
      "   2. FIPS                                               (100.0% data available)\n",
      "   3. State                                              (100.0% data available)\n",
      "   4. County                                             (100.0% data available)\n",
      "   5. # Alcohol-Impaired Driving Deaths                  (99.1% data available)\n",
      "   6. # Driving Deaths                                   (99.1% data available)\n",
      "   7. % Adults with Obesity                              (100.0% data available)\n",
      "   8. % Children in Poverty                              (99.9% data available)\n",
      "   9. % Children in Single-Parent Households             (99.9% data available)\n",
      "  10. % Drive Alone to Work                              (90.9% data available)\n",
      "  11. % Excessive Drinking                               (94.7% data available)\n",
      "  12. % Fair or Poor Health                              (97.7% data available)\n",
      "  13. % Long Commute - Drives Alone                      (100.0% data available)\n",
      "  14. % Low Birthweight                                  (96.4% data available)\n",
      "  15. % Severe Housing Problems                          (100.0% data available)\n",
      "  16. % Smokers                                          (97.5% data available)\n",
      "  17. % Some College                                     (100.0% data available)\n",
      "  18. % Unemployed                                       (99.9% data available)\n",
      "  19. % Uninsured                                        (99.9% data available)\n",
      "  20. % With Access to Exercise Opportunities            (90.0% data available)\n",
      "  21. Food Environment Index                             (99.5% data available)\n",
      "  22. Income Ratio                                       (90.8% data available)\n",
      "  23. Mentally Unhealthy Days                            (96.8% data available)\n",
      "  24. Physically Unhealthy Days                          (98.0% data available)\n",
      "  25. Premature Deaths                                   (76.0% data available)\n",
      "  26. Preventable Hospitalization Rate                   (88.7% data available)\n",
      "  27. Primary Care Physicians Rate                       (95.4% data available)\n",
      "  28. Social Association Rate                            (90.9% data available)\n",
      "  29. Teen Birth Rate                                    (95.4% data available)\n",
      "  30. Violent Crime Rate                                 (77.1% data available)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where County is null\n",
    "print(f\"Original shape: {combined_df.shape}\")\n",
    "print(f\"Rows with null County: {combined_df['County'].isna().sum()}\")\n",
    "\n",
    "# Remove rows where County is null\n",
    "combined_df_cleaned = combined_df[combined_df['County'].notna()].copy()\n",
    "\n",
    "print(f\"After removing null counties: {combined_df_cleaned.shape}\")\n",
    "\n",
    "# Calculate missing percentage for each column\n",
    "missing_percent = (combined_df_cleaned.isna().sum() / len(combined_df_cleaned)) * 100\n",
    "\n",
    "# Create a summary of missing data\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': missing_percent.index,\n",
    "    'Missing_Count': combined_df_cleaned.isna().sum().values,\n",
    "    'Total_Rows': len(combined_df_cleaned),\n",
    "    'Missing_Percentage': missing_percent.values\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Columns with missing data:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(missing_summary[missing_summary['Missing_Percentage'] > 0])\n",
    "\n",
    "# Identify columns to keep (less than or equal to 50% missing)\n",
    "columns_to_keep = missing_percent[missing_percent <= 50].index.tolist()\n",
    "columns_to_remove = missing_percent[missing_percent > 50].index.tolist()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Columns to remove (>50% missing): {len(columns_to_remove)}\")\n",
    "print(f\"{'='*60}\")\n",
    "for col in columns_to_remove:\n",
    "    print(f\"  - {col}: {missing_percent[col]:.1f}% missing\")\n",
    "\n",
    "# Keep only columns with <=50% missing data\n",
    "combined_df_cleaned = combined_df_cleaned[columns_to_keep]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Final cleaned dataset summary:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Shape: {combined_df_cleaned.shape}\")\n",
    "print(f\"Rows: {len(combined_df_cleaned)}\")\n",
    "print(f\"Columns: {len(combined_df_cleaned.columns)}\")\n",
    "print(f\"\\nRemaining columns ({len(combined_df_cleaned.columns)}):\")\n",
    "for i, col in enumerate(combined_df_cleaned.columns, 1):\n",
    "    non_missing = combined_df_cleaned[col].notna().sum()\n",
    "    pct_available = (non_missing / len(combined_df_cleaned)) * 100\n",
    "    print(f\"  {i:2d}. {col:<50} ({pct_available:.1f}% data available)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1657e52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWI Data Shape: (2642015, 24)\n",
      "\n",
      "Unique years: [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "Number of unique counties (FIPS): 3222\n",
      "Number of unique industries: 21\n",
      "Suppressed EarnBeg: 11305 records\n",
      "Suppressed Emp: 259199 records\n",
      "Suppressed HirA: 287103 records\n",
      "\n",
      "Original health data shape: (34561, 30)\n",
      "Quarterly health data shape: (138244, 31)\n",
      "\n",
      "Merged data shape: (2573811, 54)\n",
      "Number of columns: 54\n",
      "\n",
      "=== MERGE QUALITY CHECK ===\n",
      "Unique FIPS in health data: 3150\n",
      "Unique FIPS in QWI data: 3222\n",
      "Unique FIPS in merged data: 3127\n",
      "\n",
      "Records per industry in merged data:\n",
      "industry\n",
      "00       135584\n",
      "44-45    135348\n",
      "23       134964\n",
      "62       134904\n",
      "72       134797\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Year coverage in merged data:\n",
      "Year\n",
      "2014    236893\n",
      "2015    236832\n",
      "2016    236126\n",
      "2017    235371\n",
      "2018    235487\n",
      "2019    235625\n",
      "2020    235622\n",
      "2021    235941\n",
      "2022    230093\n",
      "2023    230257\n",
      "2024    225564\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== WORKFORCE METRICS SUMMARY ===\n",
      "                   Emp                      EarnBeg                  \\\n",
      "                  mean  median   count         mean  median   count   \n",
      "industry                                                              \n",
      "00        39179.571764  6320.0  135535  3546.003326  3367.0  135583   \n",
      "11          418.916579   124.0  125795  3019.946179  2883.0  132384   \n",
      "21          403.201091    83.0   65642  5422.420119  5023.0  104418   \n",
      "22          280.050694    82.0   80621  7267.053973  7065.0  120022   \n",
      "23         2345.758641   405.0  132769  3918.102888  3762.0  134846   \n",
      "\n",
      "                 HirA                  \n",
      "                 mean  median   count  \n",
      "industry                               \n",
      "00        7432.224494  1229.0  135545  \n",
      "11         207.062057    25.0  122016  \n",
      "21          49.473474     8.0   73098  \n",
      "22          13.468592     3.0   83196  \n",
      "23         511.466443    93.0  130897  \n",
      "\n",
      "County retention rate: 99.3%\n",
      "\n",
      "Final dataset: 2,573,811 records\n",
      "Unique county-year-quarter-industry combinations\n"
     ]
    }
   ],
   "source": [
    "# Read the QWI data\n",
    "qwi_path = r\"C:\\Users\\liuc\\Downloads\\qwi_47eb6eafd6f449ccbab042fc81879bc1.csv\"\n",
    "qwi_df = pd.read_csv(qwi_path)\n",
    "\n",
    "print(\"QWI Data Shape:\", qwi_df.shape)\n",
    "print(f\"\\nUnique years: {sorted(qwi_df['year'].unique())}\")\n",
    "print(f\"Number of unique counties (FIPS): {qwi_df['geography'].nunique()}\")\n",
    "print(f\"Number of unique industries: {qwi_df['industry'].nunique()}\")\n",
    "\n",
    "# Handle FIPS codes\n",
    "qwi_df['FIPS'] = qwi_df['geography'].astype(str).str.zfill(5)\n",
    "\n",
    "# Handle suppressed data\n",
    "value_cols = ['EarnBeg', 'Emp', 'HirA']\n",
    "suppression_cols = ['sEarnBeg', 'sEmp', 'sHirA']\n",
    "\n",
    "for val_col, supp_col in zip(value_cols, suppression_cols):\n",
    "    qwi_df.loc[qwi_df[supp_col] == 5, val_col] = np.nan\n",
    "    print(f\"Suppressed {val_col}: {(qwi_df[supp_col] == 5).sum()} records\")\n",
    "\n",
    "# Create quarterly version of health data\n",
    "quarters = [1, 2, 3, 4]\n",
    "health_quarterly_list = []\n",
    "\n",
    "for quarter in quarters:\n",
    "    health_q = combined_df_cleaned.copy()\n",
    "    health_q['quarter'] = quarter\n",
    "    health_quarterly_list.append(health_q)\n",
    "\n",
    "health_quarterly = pd.concat(health_quarterly_list, ignore_index=True)\n",
    "\n",
    "print(f\"\\nOriginal health data shape: {combined_df_cleaned.shape}\")\n",
    "print(f\"Quarterly health data shape: {health_quarterly.shape}\")\n",
    "\n",
    "# Ensure FIPS formatting in health data\n",
    "health_quarterly['FIPS'] = health_quarterly['FIPS'].astype(str).str.zfill(5)\n",
    "\n",
    "# Merge - note the lowercase 'year' in QWI data\n",
    "merged_df = pd.merge(\n",
    "    health_quarterly,\n",
    "    qwi_df,\n",
    "    left_on=['FIPS', 'Year', 'quarter'],\n",
    "    right_on=['FIPS', 'year', 'quarter'],\n",
    "    how='inner',\n",
    "    suffixes=('_health', '_qwi')\n",
    ")\n",
    "\n",
    "print(f\"\\nMerged data shape: {merged_df.shape}\")\n",
    "print(f\"Number of columns: {len(merged_df.columns)}\")\n",
    "\n",
    "# Check merge quality\n",
    "print(\"\\n=== MERGE QUALITY CHECK ===\")\n",
    "print(f\"Unique FIPS in health data: {health_quarterly['FIPS'].nunique()}\")\n",
    "print(f\"Unique FIPS in QWI data: {qwi_df['FIPS'].nunique()}\")\n",
    "print(f\"Unique FIPS in merged data: {merged_df['FIPS'].nunique()}\")\n",
    "\n",
    "# Check industries in merged data\n",
    "print(f\"\\nRecords per industry in merged data:\")\n",
    "print(merged_df['industry'].value_counts().head())\n",
    "\n",
    "# Check year coverage\n",
    "print(f\"\\nYear coverage in merged data:\")\n",
    "print(merged_df['Year'].value_counts().sort_index())\n",
    "\n",
    "# Basic statistics on workforce metrics\n",
    "print(\"\\n=== WORKFORCE METRICS SUMMARY ===\")\n",
    "workforce_metrics = merged_df.groupby('industry')[['Emp', 'EarnBeg', 'HirA']].agg(['mean', 'median', 'count'])\n",
    "print(workforce_metrics.head())\n",
    "\n",
    "# Check how much data we retained\n",
    "retention_rate = (merged_df['FIPS'].nunique() / health_quarterly['FIPS'].nunique()) * 100\n",
    "print(f\"\\nCounty retention rate: {retention_rate:.1f}%\")\n",
    "\n",
    "print(f\"\\nFinal dataset: {len(merged_df):,} records\")\n",
    "print(f\"Unique county-year-quarter-industry combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57232fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_columns = [col for col in combined_df_cleaned.columns if col != 'quarter']\n",
    "\n",
    "# From QWI data: only the specific columns you mentioned\n",
    "qwi_columns = ['quarter', 'EarnBeg', 'Emp', 'HirA', 'sEarnBeg', 'sEmp', 'sHirA', 'industry']\n",
    "\n",
    "# Combine the column lists\n",
    "columns_to_keep = health_columns + qwi_columns\n",
    "\n",
    "# Filter the merged dataframe\n",
    "merged_df_filtered = merged_df[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec3070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping\n",
    "industry_mapping = {\n",
    "    '00': 'Total, All Industries',\n",
    "    '11': 'Agriculture, Forestry, Fishing, and Hunting',\n",
    "    '21': 'Mining, Quarrying, and Oil and Gas Extraction',\n",
    "    '22': 'Utilities',\n",
    "    '23': 'Construction',\n",
    "    '31-33': 'Manufacturing',\n",
    "    '42': 'Wholesale Trade',\n",
    "    '44-45': 'Retail Trade',\n",
    "    '48-49': 'Transportation and Warehousing',\n",
    "    '51': 'Information',\n",
    "    '52': 'Finance and Insurance',\n",
    "    '53': 'Real Estate and Rental and Leasing',\n",
    "    '54': 'Professional, Scientific, and Technical Services',\n",
    "    '55': 'Management of Companies and Enterprises',\n",
    "    '56': 'Administrative and Support and Waste Management Services',\n",
    "    '61': 'Educational Services',\n",
    "    '62': 'Health Care and Social Assistance',\n",
    "    '71': 'Arts, Entertainment, and Recreation',\n",
    "    '72': 'Accommodation and Food Services',\n",
    "    '81': 'Other Services (except Public Administration)',\n",
    "    '92': 'Public Administration'\n",
    "}\n",
    "\n",
    "# Add readable industry name\n",
    "merged_df_filtered['industry_name'] = merged_df_filtered['industry'].map(industry_mapping)\n",
    "\n",
    "merged_df_filtered = merged_df_filtered.rename(columns={\n",
    "    'EarnBeg': 'Earnings_Beginning_Qtr',\n",
    "    'Emp': 'Employment_Count',\n",
    "    'HirA': 'New_Hires',\n",
    "    'sEarnBeg': 'Earnings_Suppression_Flag',\n",
    "    'sEmp': 'Employment_Suppression_Flag',\n",
    "    'sHirA': 'Hires_Suppression_Flag'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779a2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_path = r\"C:\\Users\\liuc\\Downloads\\Population by Age and Sex - US, States, Counties.csv\"\n",
    "df_population = pd.read_csv(population_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b143f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Year is int\n",
    "merged_df_filtered['Year'] = merged_df_filtered['Year'].astype(int)\n",
    "df_population_unique = (\n",
    "    df_population\n",
    "    .sort_values(['Statefips','Countyfips','Year'])\n",
    "    .drop_duplicates(subset=['Statefips','Countyfips','Year'], keep='first')\n",
    ")\n",
    "\n",
    "\n",
    "df_population_unique['FIPS'] = (\n",
    "    df_population_unique['Statefips'].astype(str).str.zfill(2) +\n",
    "    df_population_unique['Countyfips'].astype(str).str.zfill(3)\n",
    ")\n",
    "\n",
    "df_pop_small = df_population_unique[['FIPS','Year','Total Population']].rename(\n",
    "    columns={'Total Population':'Population'}\n",
    ")\n",
    "\n",
    "merged_full = merged_df_filtered.merge(\n",
    "    df_pop_small, on=['FIPS','Year'], how='left'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd4bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame Shape: (2151, 39)\n",
      "Sample Columns: ['State', 'Year', 'quarter', 'state_total_pop', 'state_emp_total', 'state_hires_total', 'state_avg_earnings', 'econ_emp_per_1k', 'econ_hires_per_1k', 'econ_hire_rate']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------------\n",
    "# SETUP: Define your column lists carefully\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. Variables that are RAW COUNTS -> We will SUM these\n",
    "# Note: I included 'Premature Deaths' here assuming it is a count. \n",
    "# If it is a rate (YPLL Rate), move it to the rate_cols list.\n",
    "health_count_cols = [\n",
    "    '# Alcohol-Impaired Driving Deaths', \n",
    "    '# Driving Deaths',\n",
    "    'Premature Deaths' \n",
    "]\n",
    "\n",
    "# 2. Variables that are RATES / INDICES / PERCENTS -> We will WEIGHTED AVERAGE these\n",
    "health_rate_cols = [\n",
    "    '% Adults with Obesity', \n",
    "    '% Children in Poverty',\n",
    "    '% Children in Single-Parent Households', \n",
    "    '% Drive Alone to Work',\n",
    "    '% Excessive Drinking', \n",
    "    '% Fair or Poor Health',\n",
    "    '% Long Commute - Drives Alone', \n",
    "    '% Low Birthweight',\n",
    "    '% Severe Housing Problems', \n",
    "    '% Smokers', \n",
    "    '% Some College',\n",
    "    '% Unemployed', \n",
    "    '% Uninsured',\n",
    "    '% With Access to Exercise Opportunities', \n",
    "    'Food Environment Index',\n",
    "    'Income Ratio', \n",
    "    'Mentally Unhealthy Days', \n",
    "    'Physically Unhealthy Days',\n",
    "    'Preventable Hospitalization Rate',\n",
    "    'Primary Care Physicians Rate', \n",
    "    'Social Association Rate',\n",
    "    'Teen Birth Rate', \n",
    "    'Violent Crime Rate'\n",
    "]\n",
    "\n",
    "# 3. Numeric columns to coerce (Standard housekeeping)\n",
    "numeric_cols = [\n",
    "    'Year', 'quarter', 'FIPS', 'Population',\n",
    "    'Employment_Count', 'New_Hires', 'Earnings_Beginning_Qtr'\n",
    "] + health_count_cols + health_rate_cols\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 0: PRE-PROCESSING\n",
    "# ---------------------------------------------------------\n",
    "df = merged_full.copy()\n",
    "\n",
    "# Coerce numeric types\n",
    "for c in numeric_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Filter Year Window\n",
    "df = df[(df['Year'] >= 2014) & (df['Year'] <= 2024)].copy()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 1: HEALTH DATA AGGREGATION (Annual)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Create a clean County-Year dataset\n",
    "# We drop duplicates because the original df has many rows (industries) per county\n",
    "county_health = df[['State', 'Year', 'FIPS', 'Population'] + health_count_cols + health_rate_cols].drop_duplicates()\n",
    "\n",
    "# --- A. Handle Weighted Averages (Rates) ---\n",
    "# Create numerators: (Rate * Population)\n",
    "for col in health_rate_cols:\n",
    "    county_health[f'{col}_numerator'] = county_health[col] * county_health['Population']\n",
    "\n",
    "# Define aggregation dictionary\n",
    "agg_dict = {\n",
    "    'state_total_pop': ('Population', 'sum'),\n",
    "}\n",
    "\n",
    "# Add Sum logic for Count columns\n",
    "for col in health_count_cols:\n",
    "    agg_dict[f'STATE_{col}'] = (col, 'sum')\n",
    "\n",
    "# Add Sum logic for Rate Numerators\n",
    "for col in health_rate_cols:\n",
    "    agg_dict[f'{col}_num_sum'] = (f'{col}_numerator', 'sum')\n",
    "\n",
    "# perform GroupBy\n",
    "state_health = county_health.groupby(['State', 'Year'], as_index=False).agg(**agg_dict)\n",
    "\n",
    "# Calculate Final Weighted Averages for Rates\n",
    "for col in health_rate_cols:\n",
    "    # Sum of (Rate*Pop) / Total Pop\n",
    "    state_health[f'STATE_{col}'] = state_health[f'{col}_num_sum'] / state_health['state_total_pop']\n",
    "    # Drop the temporary numerator column to keep it clean\n",
    "    state_health.drop(columns=[f'{col}_num_sum'], inplace=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2: ECONOMIC DATA AGGREGATION (Quarterly)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# CRITICAL: Filter out Industry '00' to avoid double counting\n",
    "# We sum the specific industries to get the State Total\n",
    "df_econ = df[df['industry'] != '00'].copy()\n",
    "\n",
    "# Weight Earnings by Employment (because it's an average per person)\n",
    "df_econ['wage_bill'] = df_econ['Earnings_Beginning_Qtr'] * df_econ['Employment_Count']\n",
    "\n",
    "state_qtr = (\n",
    "    df_econ.groupby(['State', 'Year', 'quarter'], as_index=False)\n",
    "    .agg(\n",
    "        state_emp_total=('Employment_Count', 'sum'),\n",
    "        state_hires_total=('New_Hires', 'sum'),\n",
    "        state_wage_bill_total=('wage_bill', 'sum')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Recover State Average Earnings\n",
    "state_qtr['state_avg_earnings'] = state_qtr['state_wage_bill_total'] / state_qtr['state_emp_total']\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 3: MERGE & FEATURE ENGINEERING\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Merge Annual Health into Quarterly Econ\n",
    "state_df = state_qtr.merge(state_health, on=['State', 'Year'], how='left')\n",
    "\n",
    "# Helper variables\n",
    "pop = state_df['state_total_pop'].replace({0: np.nan})\n",
    "emp = state_df['state_emp_total'].replace({0: np.nan})\n",
    "\n",
    "# Per Capita Econ Metrics\n",
    "state_df['econ_emp_per_1k'] = 1000 * state_df['state_emp_total'] / pop\n",
    "state_df['econ_hires_per_1k'] = 1000 * state_df['state_hires_total'] / pop\n",
    "state_df['econ_hire_rate'] = state_df['state_hires_total'] / emp\n",
    "\n",
    "# Growth Rates (Lagged features)\n",
    "state_df = state_df.sort_values(['State', 'Year', 'quarter'])\n",
    "\n",
    "def calc_growth(series, lag):\n",
    "    prev = series.shift(lag)\n",
    "    den = prev.replace({0: np.nan})\n",
    "    return (series - prev) / den\n",
    "\n",
    "# QoQ Growth\n",
    "state_df['growth_emp_qoq'] = state_df.groupby('State')['state_emp_total'].transform(lambda x: calc_growth(x, 1))\n",
    "state_df['growth_earn_qoq'] = state_df.groupby('State')['state_avg_earnings'].transform(lambda x: calc_growth(x, 1))\n",
    "\n",
    "# YoY Growth (Seasonality adjustment)\n",
    "state_df['growth_emp_yoy'] = state_df.groupby('State')['state_emp_total'].transform(lambda x: calc_growth(x, 4))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 4: CLEANUP & FINAL OUTPUT\n",
    "# ---------------------------------------------------------\n",
    "state_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Organize columns clearly\n",
    "final_cols = [\n",
    "    'State', 'Year', 'quarter', 'state_total_pop',\n",
    "    # Econ\n",
    "    'state_emp_total', 'state_hires_total', 'state_avg_earnings',\n",
    "    'econ_emp_per_1k', 'econ_hires_per_1k', 'econ_hire_rate',\n",
    "    'growth_emp_qoq', 'growth_earn_qoq', 'growth_emp_yoy'\n",
    "] \n",
    "# Add all the State Health Columns (Counts and Rates)\n",
    "# (They are already named STATE_... in the dataframe)\n",
    "health_final_cols = [c for c in state_df.columns if c.startswith('STATE_')]\n",
    "final_cols = final_cols + health_final_cols\n",
    "\n",
    "# Final Selection\n",
    "state_df_final = state_df[final_cols]\n",
    "\n",
    "print(f\"Aggregated DataFrame Shape: {state_df_final.shape}\")\n",
    "print(\"Sample Columns:\", state_df_final.columns.tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df_filtered = pd.read_csv(r\"C:\\Users\\liuc\\Downloads\\CH_ECON_V1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e61eb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>state_total_pop</th>\n",
       "      <th>state_emp_total</th>\n",
       "      <th>state_hires_total</th>\n",
       "      <th>state_avg_earnings</th>\n",
       "      <th>econ_emp_per_1k</th>\n",
       "      <th>econ_hires_per_1k</th>\n",
       "      <th>econ_hire_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE_% With Access to Exercise Opportunities</th>\n",
       "      <th>STATE_Food Environment Index</th>\n",
       "      <th>STATE_Income Ratio</th>\n",
       "      <th>STATE_Mentally Unhealthy Days</th>\n",
       "      <th>STATE_Physically Unhealthy Days</th>\n",
       "      <th>STATE_Preventable Hospitalization Rate</th>\n",
       "      <th>STATE_Primary Care Physicians Rate</th>\n",
       "      <th>STATE_Social Association Rate</th>\n",
       "      <th>STATE_Teen Birth Rate</th>\n",
       "      <th>STATE_Violent Crime Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4843737.0</td>\n",
       "      <td>1484428.0</td>\n",
       "      <td>234866.0</td>\n",
       "      <td>3183.492990</td>\n",
       "      <td>306.463377</td>\n",
       "      <td>48.488595</td>\n",
       "      <td>0.158220</td>\n",
       "      <td>...</td>\n",
       "      <td>51.935239</td>\n",
       "      <td>6.932836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.254047</td>\n",
       "      <td>4.289236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.132991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.186843</td>\n",
       "      <td>410.745302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>4843737.0</td>\n",
       "      <td>1488384.0</td>\n",
       "      <td>296168.0</td>\n",
       "      <td>3186.477239</td>\n",
       "      <td>307.280102</td>\n",
       "      <td>61.144525</td>\n",
       "      <td>0.198986</td>\n",
       "      <td>...</td>\n",
       "      <td>51.935239</td>\n",
       "      <td>6.932836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.254047</td>\n",
       "      <td>4.289236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.132991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.186843</td>\n",
       "      <td>410.745302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>4843737.0</td>\n",
       "      <td>1510987.0</td>\n",
       "      <td>292385.0</td>\n",
       "      <td>3158.744593</td>\n",
       "      <td>311.946540</td>\n",
       "      <td>60.363517</td>\n",
       "      <td>0.193506</td>\n",
       "      <td>...</td>\n",
       "      <td>51.935239</td>\n",
       "      <td>6.932836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.254047</td>\n",
       "      <td>4.289236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.132991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.186843</td>\n",
       "      <td>410.745302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>4843737.0</td>\n",
       "      <td>1509475.0</td>\n",
       "      <td>273242.0</td>\n",
       "      <td>3383.957254</td>\n",
       "      <td>311.634385</td>\n",
       "      <td>56.411403</td>\n",
       "      <td>0.181018</td>\n",
       "      <td>...</td>\n",
       "      <td>51.935239</td>\n",
       "      <td>6.932836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.254047</td>\n",
       "      <td>4.289236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.132991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.186843</td>\n",
       "      <td>410.745302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4854803.0</td>\n",
       "      <td>1510048.0</td>\n",
       "      <td>246062.0</td>\n",
       "      <td>3224.297608</td>\n",
       "      <td>311.042075</td>\n",
       "      <td>50.684240</td>\n",
       "      <td>0.162950</td>\n",
       "      <td>...</td>\n",
       "      <td>64.355654</td>\n",
       "      <td>6.694086</td>\n",
       "      <td>5.030240</td>\n",
       "      <td>4.252503</td>\n",
       "      <td>4.285823</td>\n",
       "      <td>69.088952</td>\n",
       "      <td>62.883135</td>\n",
       "      <td>12.483551</td>\n",
       "      <td>46.968524</td>\n",
       "      <td>410.093125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>578239.0</td>\n",
       "      <td>215710.0</td>\n",
       "      <td>45344.0</td>\n",
       "      <td>4717.370878</td>\n",
       "      <td>373.046439</td>\n",
       "      <td>78.417402</td>\n",
       "      <td>0.210208</td>\n",
       "      <td>...</td>\n",
       "      <td>77.638870</td>\n",
       "      <td>7.779140</td>\n",
       "      <td>4.235807</td>\n",
       "      <td>4.019662</td>\n",
       "      <td>2.849604</td>\n",
       "      <td>2324.557970</td>\n",
       "      <td>70.486996</td>\n",
       "      <td>11.973542</td>\n",
       "      <td>24.269712</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>580752.0</td>\n",
       "      <td>208388.0</td>\n",
       "      <td>36781.0</td>\n",
       "      <td>4665.328800</td>\n",
       "      <td>358.824421</td>\n",
       "      <td>63.333402</td>\n",
       "      <td>0.176502</td>\n",
       "      <td>...</td>\n",
       "      <td>77.761949</td>\n",
       "      <td>7.781328</td>\n",
       "      <td>4.259097</td>\n",
       "      <td>4.750646</td>\n",
       "      <td>3.437344</td>\n",
       "      <td>2178.144266</td>\n",
       "      <td>70.319097</td>\n",
       "      <td>12.253024</td>\n",
       "      <td>20.177949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>580752.0</td>\n",
       "      <td>208453.0</td>\n",
       "      <td>59642.0</td>\n",
       "      <td>4530.285609</td>\n",
       "      <td>358.936345</td>\n",
       "      <td>102.697881</td>\n",
       "      <td>0.286117</td>\n",
       "      <td>...</td>\n",
       "      <td>77.761949</td>\n",
       "      <td>7.781328</td>\n",
       "      <td>4.259097</td>\n",
       "      <td>4.750646</td>\n",
       "      <td>3.437344</td>\n",
       "      <td>2178.144266</td>\n",
       "      <td>70.319097</td>\n",
       "      <td>12.253024</td>\n",
       "      <td>20.177949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>580752.0</td>\n",
       "      <td>222565.0</td>\n",
       "      <td>51118.0</td>\n",
       "      <td>4574.083715</td>\n",
       "      <td>383.235873</td>\n",
       "      <td>88.020360</td>\n",
       "      <td>0.229677</td>\n",
       "      <td>...</td>\n",
       "      <td>77.761949</td>\n",
       "      <td>7.781328</td>\n",
       "      <td>4.259097</td>\n",
       "      <td>4.750646</td>\n",
       "      <td>3.437344</td>\n",
       "      <td>2178.144266</td>\n",
       "      <td>70.319097</td>\n",
       "      <td>12.253024</td>\n",
       "      <td>20.177949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>580752.0</td>\n",
       "      <td>217840.0</td>\n",
       "      <td>41963.0</td>\n",
       "      <td>4891.206367</td>\n",
       "      <td>375.099871</td>\n",
       "      <td>72.256316</td>\n",
       "      <td>0.192632</td>\n",
       "      <td>...</td>\n",
       "      <td>77.761949</td>\n",
       "      <td>7.781328</td>\n",
       "      <td>4.259097</td>\n",
       "      <td>4.750646</td>\n",
       "      <td>3.437344</td>\n",
       "      <td>2178.144266</td>\n",
       "      <td>70.319097</td>\n",
       "      <td>12.253024</td>\n",
       "      <td>20.177949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2151 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Year  quarter  state_total_pop  state_emp_total  \\\n",
       "0     Alabama  2014        1        4843737.0        1484428.0   \n",
       "1     Alabama  2014        2        4843737.0        1488384.0   \n",
       "2     Alabama  2014        3        4843737.0        1510987.0   \n",
       "3     Alabama  2014        4        4843737.0        1509475.0   \n",
       "4     Alabama  2015        1        4854803.0        1510048.0   \n",
       "...       ...   ...      ...              ...              ...   \n",
       "2146  Wyoming  2023        4         578239.0         215710.0   \n",
       "2147  Wyoming  2024        1         580752.0         208388.0   \n",
       "2148  Wyoming  2024        2         580752.0         208453.0   \n",
       "2149  Wyoming  2024        3         580752.0         222565.0   \n",
       "2150  Wyoming  2024        4         580752.0         217840.0   \n",
       "\n",
       "      state_hires_total  state_avg_earnings  econ_emp_per_1k  \\\n",
       "0              234866.0         3183.492990       306.463377   \n",
       "1              296168.0         3186.477239       307.280102   \n",
       "2              292385.0         3158.744593       311.946540   \n",
       "3              273242.0         3383.957254       311.634385   \n",
       "4              246062.0         3224.297608       311.042075   \n",
       "...                 ...                 ...              ...   \n",
       "2146            45344.0         4717.370878       373.046439   \n",
       "2147            36781.0         4665.328800       358.824421   \n",
       "2148            59642.0         4530.285609       358.936345   \n",
       "2149            51118.0         4574.083715       383.235873   \n",
       "2150            41963.0         4891.206367       375.099871   \n",
       "\n",
       "      econ_hires_per_1k  econ_hire_rate  ...  \\\n",
       "0             48.488595        0.158220  ...   \n",
       "1             61.144525        0.198986  ...   \n",
       "2             60.363517        0.193506  ...   \n",
       "3             56.411403        0.181018  ...   \n",
       "4             50.684240        0.162950  ...   \n",
       "...                 ...             ...  ...   \n",
       "2146          78.417402        0.210208  ...   \n",
       "2147          63.333402        0.176502  ...   \n",
       "2148         102.697881        0.286117  ...   \n",
       "2149          88.020360        0.229677  ...   \n",
       "2150          72.256316        0.192632  ...   \n",
       "\n",
       "      STATE_% With Access to Exercise Opportunities  \\\n",
       "0                                         51.935239   \n",
       "1                                         51.935239   \n",
       "2                                         51.935239   \n",
       "3                                         51.935239   \n",
       "4                                         64.355654   \n",
       "...                                             ...   \n",
       "2146                                      77.638870   \n",
       "2147                                      77.761949   \n",
       "2148                                      77.761949   \n",
       "2149                                      77.761949   \n",
       "2150                                      77.761949   \n",
       "\n",
       "      STATE_Food Environment Index  STATE_Income Ratio  \\\n",
       "0                         6.932836            0.000000   \n",
       "1                         6.932836            0.000000   \n",
       "2                         6.932836            0.000000   \n",
       "3                         6.932836            0.000000   \n",
       "4                         6.694086            5.030240   \n",
       "...                            ...                 ...   \n",
       "2146                      7.779140            4.235807   \n",
       "2147                      7.781328            4.259097   \n",
       "2148                      7.781328            4.259097   \n",
       "2149                      7.781328            4.259097   \n",
       "2150                      7.781328            4.259097   \n",
       "\n",
       "      STATE_Mentally Unhealthy Days  STATE_Physically Unhealthy Days  \\\n",
       "0                          4.254047                         4.289236   \n",
       "1                          4.254047                         4.289236   \n",
       "2                          4.254047                         4.289236   \n",
       "3                          4.254047                         4.289236   \n",
       "4                          4.252503                         4.285823   \n",
       "...                             ...                              ...   \n",
       "2146                       4.019662                         2.849604   \n",
       "2147                       4.750646                         3.437344   \n",
       "2148                       4.750646                         3.437344   \n",
       "2149                       4.750646                         3.437344   \n",
       "2150                       4.750646                         3.437344   \n",
       "\n",
       "      STATE_Preventable Hospitalization Rate  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.000000   \n",
       "2                                   0.000000   \n",
       "3                                   0.000000   \n",
       "4                                  69.088952   \n",
       "...                                      ...   \n",
       "2146                             2324.557970   \n",
       "2147                             2178.144266   \n",
       "2148                             2178.144266   \n",
       "2149                             2178.144266   \n",
       "2150                             2178.144266   \n",
       "\n",
       "      STATE_Primary Care Physicians Rate  STATE_Social Association Rate  \\\n",
       "0                              62.132991                       0.000000   \n",
       "1                              62.132991                       0.000000   \n",
       "2                              62.132991                       0.000000   \n",
       "3                              62.132991                       0.000000   \n",
       "4                              62.883135                      12.483551   \n",
       "...                                  ...                            ...   \n",
       "2146                           70.486996                      11.973542   \n",
       "2147                           70.319097                      12.253024   \n",
       "2148                           70.319097                      12.253024   \n",
       "2149                           70.319097                      12.253024   \n",
       "2150                           70.319097                      12.253024   \n",
       "\n",
       "      STATE_Teen Birth Rate  STATE_Violent Crime Rate  \n",
       "0                 48.186843                410.745302  \n",
       "1                 48.186843                410.745302  \n",
       "2                 48.186843                410.745302  \n",
       "3                 48.186843                410.745302  \n",
       "4                 46.968524                410.093125  \n",
       "...                     ...                       ...  \n",
       "2146              24.269712                  0.000000  \n",
       "2147              20.177949                  0.000000  \n",
       "2148              20.177949                  0.000000  \n",
       "2149              20.177949                  0.000000  \n",
       "2150              20.177949                  0.000000  \n",
       "\n",
       "[2151 rows x 39 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bf732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a74c7da0f847ea803d28954916cf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Variable:', index=26, layout=Layout(width='450px'), options=('STATE_# Alcâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201ade5d4e804ed9aa8b8610ec11aca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# US State Choropleth (Using state_df_final)\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from ipywidgets import widgets, interactive_output\n",
    "from IPython.display import display\n",
    "\n",
    "# 1. Prepare the Data\n",
    "# --------------------------------------------\n",
    "# We group by State/Year and take the MEAN.\n",
    "# - For Health data (Annual): The value is constant across quarters, so Mean returns the value.\n",
    "# - For Econ data (Quarterly): This gives us the \"Average Quarterly\" level for that year.\n",
    "df_map = state_df_final.groupby(['State', 'Year'], as_index=False).mean(numeric_only=True)\n",
    "\n",
    "# 2. Map State Names to USPS Codes\n",
    "# --------------------------------------------\n",
    "state_to_code = {\n",
    "    'Alabama':'AL','Alaska':'AK','Arizona':'AZ','Arkansas':'AR','California':'CA','Colorado':'CO',\n",
    "    'Connecticut':'CT','Delaware':'DE','District of Columbia':'DC','Florida':'FL','Georgia':'GA',\n",
    "    'Hawaii':'HI','Idaho':'ID','Illinois':'IL','Indiana':'IN','Iowa':'IA','Kansas':'KS','Kentucky':'KY',\n",
    "    'Louisiana':'LA','Maine':'ME','Maryland':'MD','Massachusetts':'MA','Michigan':'MI','Minnesota':'MN',\n",
    "    'Mississippi':'MS','Missouri':'MO','Montana':'MT','Nebraska':'NE','Nevada':'NV','New Hampshire':'NH',\n",
    "    'New Jersey':'NJ','New Mexico':'NM','New York':'NY','North Carolina':'NC','North Dakota':'ND',\n",
    "    'Ohio':'OH','Oklahoma':'OK','Oregon':'OR','Pennsylvania':'PA','Rhode Island':'RI','South Carolina':'SC',\n",
    "    'South Dakota':'SD','Tennessee':'TN','Texas':'TX','Utah':'UT','Vermont':'VT','Virginia':'VA',\n",
    "    'Washington':'WA','West Virginia':'WV','Wisconsin':'WI','Wyoming':'WY'\n",
    "}\n",
    "\n",
    "df_map['code'] = df_map['State'].map(state_to_code)\n",
    "\n",
    "# 3. Define Columns for Dropdown\n",
    "# --------------------------------------------\n",
    "# We dynamically pull the columns available in your dataframe\n",
    "# to ensure the dropdown never breaks.\n",
    "exclude_cols = ['State', 'Year', 'quarter', 'code', 'state_total_pop']\n",
    "available_cols = [c for c in df_map.columns if c not in exclude_cols]\n",
    "available_cols.sort()\n",
    "\n",
    "# Set a smart default\n",
    "default_val = 'econ_emp_per_1k' if 'econ_emp_per_1k' in available_cols else available_cols[0]\n",
    "\n",
    "# 4. Widgets\n",
    "# --------------------------------------------\n",
    "var_dd = widgets.Dropdown(\n",
    "    options=available_cols,\n",
    "    value=default_val,\n",
    "    description='Variable:',\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "yrs = sorted(df_map['Year'].unique())\n",
    "year_dd = widgets.Dropdown(\n",
    "    options=yrs,\n",
    "    value=yrs[-1], # Default to latest year\n",
    "    description='Year:',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "# 5. Custom Colorscale (Your Preferred Yellow-Gold)\n",
    "# --------------------------------------------\n",
    "ylw_scale = [\n",
    "    (0.00, \"#fffde7\"),\n",
    "    (0.33, \"#fff59d\"),\n",
    "    (0.66, \"#fdd835\"),\n",
    "    (1.00, \"#f9a825\")\n",
    "]\n",
    "\n",
    "# 6. Plot Function\n",
    "# --------------------------------------------\n",
    "def show_map(variable, year):\n",
    "    # Filter data for specific year\n",
    "    d = df_map[df_map['Year'] == year].copy()\n",
    "\n",
    "    # Dynamic Range calculation for better contrast\n",
    "    # (Avoids 0s or NaNs skewing the scale)\n",
    "    valid_values = d[variable].dropna()\n",
    "    if len(valid_values) > 0:\n",
    "        low = valid_values.quantile(0.05)\n",
    "        high = valid_values.quantile(0.95)\n",
    "        rc = [low, high]\n",
    "    else:\n",
    "        rc = None\n",
    "\n",
    "    fig = px.choropleth(\n",
    "        d,\n",
    "        locations=\"code\",\n",
    "        locationmode=\"USA-states\",\n",
    "        color=variable,\n",
    "        scope=\"usa\",\n",
    "        range_color=rc,\n",
    "        color_continuous_scale=ylw_scale,\n",
    "        hover_name=\"State\",\n",
    "        hover_data={'code':False, 'Year':True, variable:':.2f'},\n",
    "        labels={variable: variable.replace('_',' ').replace('STATE', '').title()}\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f\"US States â€” {variable.replace('_',' ').title()} ({year})\",\n",
    "            x=0.5,\n",
    "            xanchor='center'\n",
    "        ),\n",
    "        coloraxis_colorbar=dict(title=\"Value\"),\n",
    "        geo=dict(bgcolor='rgba(0,0,0,0)'), # Transparent geo background\n",
    "        width=1050,\n",
    "        height=600,\n",
    "        margin=dict(l=0,r=0,t=60,b=0)\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker_line_color=\"white\", marker_line_width=0.5)\n",
    "    fig.show()\n",
    "\n",
    "# 7. Display UI\n",
    "# --------------------------------------------\n",
    "ui = widgets.HBox([var_dd, year_dd])\n",
    "out = interactive_output(show_map, {'variable': var_dd, 'year': year_dd})\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9471c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuc\\AppData\\Local\\Temp\\ipykernel_24748\\2192016559.py:33: DeprecationWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926288d3dcb946f4925e3f9be1198de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='State:', layout=Layout(width='250px'), options=('Alabama',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5752874418b45a5922d5089ad5a84e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Interactive State Trend Plot (2014â€“2024)\n",
    "# Using pre-aggregated 'state_df_final'\n",
    "# ========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interactive_output\n",
    "from IPython.display import display\n",
    "\n",
    "# --------------------------------------\n",
    "# 1) Prepare Annual Data\n",
    "# --------------------------------------\n",
    "# We start with state_df_final (Quarterly) and collapse to Annual.\n",
    "# Logic:\n",
    "# - Health columns are constant for the year, so mean() returns the correct value.\n",
    "# - Econ columns are quarterly, so mean() gives the \"Average Quarterly Level\" for that year.\n",
    "df_trend = state_df_final.groupby(['State', 'Year'], as_index=False).mean(numeric_only=True)\n",
    "\n",
    "# Ensure full 2014-2024 range for every state (handling missing years)\n",
    "def _complete_years(g):\n",
    "    # Create reference index\n",
    "    all_years = pd.DataFrame({'Year': np.arange(2014, 2025)})\n",
    "    # Merge existing data onto it\n",
    "    g = all_years.merge(g, on='Year', how='left')\n",
    "    # Fill State name downwards and upwards\n",
    "    g['State'] = g['State'].ffill().bfill()\n",
    "    return g\n",
    "\n",
    "df_trend = (\n",
    "    df_trend.groupby('State', as_index=False, group_keys=False)\n",
    "    .apply(_complete_years)\n",
    "    .sort_values(['State', 'Year'])\n",
    ")\n",
    "\n",
    "# --------------------------------------\n",
    "# 2) Define Variables for Dropdowns\n",
    "# --------------------------------------\n",
    "exclude_cols = ['State', 'Year', 'quarter', 'state_total_pop']\n",
    "# Get all numeric columns except the excluded ones\n",
    "all_vars = sorted([c for c in df_trend.columns if c not in exclude_cols])\n",
    "\n",
    "state_options = sorted(df_trend['State'].dropna().unique().tolist())\n",
    "\n",
    "# --------------------------------------\n",
    "# 3) Widgets\n",
    "# --------------------------------------\n",
    "state_dd = widgets.Dropdown(\n",
    "    options=state_options,\n",
    "    value=state_options[0] if state_options else None,\n",
    "    description='State:',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "var1_dd = widgets.Dropdown(\n",
    "    options=all_vars,\n",
    "    value='econ_emp_per_1k' if 'econ_emp_per_1k' in all_vars else all_vars[0],\n",
    "    description='Variable 1:',\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Try to find a good default for Var 2 (e.g., Obesity)\n",
    "default_v2 = [v for v in all_vars if 'Obesity' in v]\n",
    "default_v2 = default_v2[0] if default_v2 else (all_vars[1] if len(all_vars) > 1 else all_vars[0])\n",
    "\n",
    "var2_dd = widgets.Dropdown(\n",
    "    options=all_vars,\n",
    "    value=default_v2,\n",
    "    description='Variable 2:',\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "normalize_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Normalize (0â€“1)',\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "# --------------------------------------\n",
    "# 4) Plotting Function\n",
    "# --------------------------------------\n",
    "def plot_state_trends(state, var1, var2, normalize):\n",
    "    if not state or not var1 or not var2:\n",
    "        return\n",
    "\n",
    "    # Filter data\n",
    "    sub = df_trend[df_trend['State'] == state].copy()\n",
    "    \n",
    "    x = sub['Year']\n",
    "    y1 = sub[var1]\n",
    "    y2 = sub[var2]\n",
    "\n",
    "    # --- Normalization Logic ---\n",
    "    def _minmax(s):\n",
    "        mn, mx = s.min(), s.max()\n",
    "        if pd.isna(mn) or pd.isna(mx) or mx == mn:\n",
    "            return s\n",
    "        return (s - mn) / (mx - mn)\n",
    "\n",
    "    if normalize:\n",
    "        y1_plot = _minmax(y1)\n",
    "        y2_plot = _minmax(y2)\n",
    "        y1_lbl = f\"{var1} (Scaled)\"\n",
    "        y2_lbl = f\"{var2} (Scaled)\"\n",
    "    else:\n",
    "        y1_plot, y2_plot = y1, y2\n",
    "        y1_lbl = var1\n",
    "        y2_lbl = var2\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Style 1\n",
    "    color1 = \"#1f77b4\" # Tab:Blue\n",
    "    line1 = ax1.plot(x, y1_plot, marker='o', linestyle='-', linewidth=2, color=color1, label=y1_lbl)\n",
    "    ax1.set_xlabel(\"Year\", fontsize=10)\n",
    "    ax1.set_ylabel(y1_lbl, color=color1, fontsize=10, fontweight='bold')\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Style 2 (Twin Axis)\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = \"#ff7f0e\" # Tab:Orange\n",
    "    line2 = ax2.plot(x, y2_plot, marker='s', linestyle='--', linewidth=2, color=color2, label=y2_lbl)\n",
    "    ax2.set_ylabel(y2_lbl, color=color2, fontsize=10, fontweight='bold')\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    # Title\n",
    "    norm_txt = \" (Normalized Trend)\" if normalize else \"\"\n",
    "    plt.title(f\"{state}: {var1} vs. {var2}{norm_txt}\", fontsize=12)\n",
    "    plt.xticks(np.arange(2014, 2025, 1))\n",
    "\n",
    "    # Unified Legend\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper left', frameon=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------------------\n",
    "# 5) Display\n",
    "# --------------------------------------\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([state_dd, normalize_cb]),\n",
    "    widgets.HBox([var1_dd, var2_dd])\n",
    "])\n",
    "\n",
    "out = interactive_output(\n",
    "    plot_state_trends,\n",
    "    {'state': state_dd, 'var1': var1_dd, 'var2': var2_dd, 'normalize': normalize_cb}\n",
    ")\n",
    "\n",
    "display(ui, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
